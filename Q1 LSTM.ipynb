{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM: Train an LSTM to mimic Russell’s style and thoughts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "import keras\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "#convert to lowercase \n",
    "book_text = open(\"book1.txt\",encoding='utf-8').read()\n",
    "\n",
    "book_text = book_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use a character-level representation for this model by using extended ASCII that has N = 256 characters. Each character will be encoded into a an integer using its ASCII code. Rescale the integers to the range [0, 1], because LSTM uses a sigmoid activation function. LSTM will receive the rescaled integers as its input¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Getting unique charachters from the whole text and the assigning then the integers.\n",
    "sort = sorted(list(set(book_text)))\n",
    "\n",
    "conv_int = dict((c, i) for i, c in enumerate(sort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_char = len(book_text)\n",
    "no_of_vocab = len(sort)\n",
    "\n",
    "model = Sequential()\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "X_Val = []\n",
    "Y_val= []\n",
    "for i in range(0, no_of_char - seq_length, 1): \n",
    "    seq_in = book_text[i:i + seq_length]\n",
    "    seq_out = book_text[i + seq_length]\n",
    "    X_Val.append([conv_int[char] for char in seq_in])\n",
    "    Y_val.append(conv_int[seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_patterns = len(X_Val)\n",
    "\n",
    "X = np.reshape(X_Val, (no_of_patterns, seq_length, 1))\n",
    "\n",
    "\n",
    "X = X / float(no_of_vocab)\n",
    "\n",
    "y = np_utils.to_categorical(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  1577211\n",
      "Total Vocab:  99\n",
      "Epoch 1/1\n",
      "1577111/1577111 [==============================] - 5999s 4ms/step - loss: 2.7270\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.72699, saving model to weights-improvement-01-2.7270.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc391772908>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X, y, epochs=20 , batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is run for the 20 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "considering_file_name = \"weights-improvement-16-1.8327.hdf5\"\n",
    "model.load_weights(considering_file_name)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "int_to_char = dict((i, c) for i, c in enumerate(sort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e ase aod to be seet to be seet the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the semse-data which is the sems"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "p=\"There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.\"\n",
    "pattern=[conv_int[char] for char in p.lower()]\n",
    "pattern=pattern[0:100]\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(no_of_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
